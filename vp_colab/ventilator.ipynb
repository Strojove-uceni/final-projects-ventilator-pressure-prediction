{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/final-projects-ventilator-pressure-prediction/blob/main/vp_colab/ventilator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BV2y2HBV-oNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a2cwnVba9rMD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import datetime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "v1x2-QxM-qOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a file for models\n",
        "file_path = f'models/{datetime.datetime.now().strftime(\"%Y %H:%M\")}'\n",
        "if os.path.exists(file_path) == False:\n",
        "  os.makedirs(file_path)\n"
      ],
      "metadata": {
        "id": "yIUjfLZH8UM5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/panekvit/su_data.git"
      ],
      "metadata": {
        "id": "tKd4Ea9LfTe2",
        "outputId": "67af0f36-261a-47ed-b448-9bfee3fc5aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'su_data'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data = pd.read_csv('/content/su_data/data.csv')\n",
        "target_pres = data.pressure.copy()"
      ],
      "metadata": {
        "id": "telloKHT-skW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "wFxIgTWh_csW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "PS59zjkzCoEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['step'] = list(range(80))*data['breath_id'].nunique()\n",
        "data['u_in_min'] = data['breath_id'].map(data.groupby('breath_id')['u_in'].min())\n",
        "\n",
        "data['u_in_diff'] = data['u_in'].diff()\n",
        "data.loc[data['step']<1, 'u_in_diff'] = 0\n",
        "\n",
        "data['time_diff'] = data['time_step'].diff()\n",
        "data.loc[data['step']<1, 'time_diff'] = 0\n",
        "\n",
        "data['inhaled_air'] = data['time_diff']*data['u_in']\n",
        "\n",
        "data['inhaled_diff_lag'] = data['inhaled_air'].diff().shift(1)\n",
        "data.loc[data['step']<2, 'inhaled_diff_lag'] = 0\n",
        "\n",
        "\n",
        "\n",
        "#data['pressure'] = data['pressure'].diff()\n",
        "#data.loc[data['step']<1, 'pressure'] = 0\n",
        "\n",
        "#Make a lead\n",
        "#df['pressure_lead'] = df.pressure.shift(-1)"
      ],
      "metadata": {
        "id": "mU2gpMgj_7R_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lag functions\n"
      ],
      "metadata": {
        "id": "WjdCaEVWDHV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_all(df, lags):\n",
        "  res = df.copy()\n",
        "  for lag in lags:\n",
        "    df1 = df.copy()\n",
        "    df1 = df1.shift(lag)\n",
        "    res = pd.merge(res,df1.rename(columns = lambda x: x+f'_{lag}lag'),left_index=True,right_index=True)\n",
        "  \n",
        "  return res\n",
        "\n",
        "def create_lag_feature(df, lags, features):\n",
        "  res = df.copy()\n",
        "  for feature in features:\n",
        "    for lag in lags:\n",
        "      df1 = df.copy()\n",
        "      df1 = df1[feature].shift(lag)\n",
        "      df1 = pd.DataFrame(df1)\n",
        "      res = pd.merge(res,df1.rename(columns = lambda x: x+f'_{lag}lag'),left_index=True,right_index=True)    \n",
        "      res.loc[res['step']<lag, feature+f'_{lag}lag'] = 0\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "kzMebL8lDGsT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN, LSTM, GRU"
      ],
      "metadata": {
        "id": "rt4FaK8VCU-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rMDxaevLU_E4",
        "outputId": "c167f740-1c96-4ba1-879e-893934b7faf8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions and Classes"
      ],
      "metadata": {
        "id": "Y5EFPKXynEk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess\n"
      ],
      "metadata": {
        "id": "3ny2dSzZnJh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHot encoding\n",
        "\n",
        "def onehot_encode_pd(df, col_name):\n",
        "    dummies = pd.get_dummies(df[col_name], prefix=col_name)\n",
        "    return pd.concat([df, dummies], axis=1).drop(columns=[col_name])\n",
        "\n",
        "# Feature label split\n",
        "\n",
        "def feature_label_split(df, target_col):\n",
        "    y = df[[target_col]]\n",
        "    X = df.drop(columns=[target_col])\n",
        "    return X, y\n",
        "\n",
        "# Split function\n",
        "\n",
        "def train_val_test_split(df, target_col, test_ratio, random_state):\n",
        "    val_ratio = test_ratio / (1 - test_ratio)\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False, random_state=random_state)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False, random_state=random_state)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Scalers\n",
        "\n",
        "def get_scaler(scaler):\n",
        "    scalers = {\n",
        "        \"minmax\": MinMaxScaler,\n",
        "        \"standard\": StandardScaler,\n",
        "        \"maxabs\": MaxAbsScaler,\n",
        "        \"robust\": RobustScaler,\n",
        "    }\n",
        "    return scalers.get(scaler.lower())()\n"
      ],
      "metadata": {
        "id": "QfMuup4ZCXzy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "6Tp9xljlnQSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # RNN layers\n",
        "        self.rnn = nn.RNN(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, h0 = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fD9NjNS0HfYJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "z_2yP29aJG_4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "-pcNYmfBJL3C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        \"rnn\": RNNModel,\n",
        "        \"lstm\": LSTMModel,\n",
        "        \"gru\": GRUModel,\n",
        "    }\n",
        "    return models.get(model.lower())(**model_params)"
      ],
      "metadata": {
        "id": "kbmh1ufvJOxJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and eval"
      ],
      "metadata": {
        "id": "8TCVjphGndP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "    \n",
        "    def train_step(self, x, y):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size=80, n_epochs=50, n_features=1, model_path = 'model'):\n",
        "\n",
        "      for epoch in range(1, n_epochs + 1):\n",
        "          batch_losses = []\n",
        "          for x_batch, y_batch in train_loader:\n",
        "              x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
        "              y_batch = y_batch.to(device)\n",
        "              loss = self.train_step(x_batch, y_batch)\n",
        "              batch_losses.append(loss)\n",
        "          training_loss = np.mean(batch_losses)\n",
        "          self.train_losses.append(training_loss)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              batch_val_losses = []\n",
        "              for x_val, y_val in val_loader:\n",
        "                  x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
        "                  y_val = y_val.to(device)\n",
        "                  self.model.eval()\n",
        "                  yhat = self.model(x_val)\n",
        "                  val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                  batch_val_losses.append(val_loss)\n",
        "              validation_loss = np.mean(batch_val_losses)\n",
        "              self.val_losses.append(validation_loss)\n",
        "\n",
        "          if (epoch <= 10) | (epoch % 50 == 0):\n",
        "              print(\n",
        "                  f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "              )\n",
        "      torch.save(self.model.state_dict(), model_path)\n",
        "      val_loss = pd.DataFrame(self.val_losses)\n",
        "      train_loss = pd.DataFrame(self.train_losses)\n",
        "      losses = pd.concat([train_loss, val_loss], axis = 1)\n",
        "      losses.columns = ['train_loss','val_loss']\n",
        "      losses.to_csv(file_path + '/losses.csv')\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
        "      with torch.no_grad():\n",
        "          predictions = []\n",
        "          values = []\n",
        "          for x_test, y_test in test_loader:\n",
        "              x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
        "              y_test = y_test.to(device)\n",
        "              self.model.eval()\n",
        "              yhat = self.model(x_test)\n",
        "              predictions.append(yhat.to('cpu').detach().numpy())\n",
        "              values.append(y_test.to('cpu').detach().numpy())\n",
        "\n",
        "      return predictions, values\n",
        "\n",
        "    def plot_losses(self, file_path):\n",
        "      plt.plot(self.train_losses, label=\"Training loss\")\n",
        "      plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "      plt.legend()\n",
        "      plt.title(\"Losses\")\n",
        "      fig1 = plt.gcf()\n",
        "      plt.show()\n",
        "      fig1.savefig(file_path + '/plot_loss.png', dpi=100)\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "PtDwfDyUJYTr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "NYAP_2k7nuaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaler, df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = scaler.inverse_transform(df[col])\n",
        "    return df\n",
        "\n",
        "\n",
        "def format_predictions(predictions, values, df_test, scaler):\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
        "    df_result = df_result.sort_index()\n",
        "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
        "    return df_result\n",
        "\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    return {'mae' : mean_absolute_error(df.value, df.prediction),\n",
        "            'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
        "            'r2' : r2_score(df.value, df.prediction)}\n",
        "\n"
      ],
      "metadata": {
        "id": "l9JEhyMnKl9x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "a0trz48zn8cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r7Mkmm-AdDA2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "jR3V5UBcoZBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick data and do OneHot\n",
        "\n",
        "df = data.copy()\n",
        "df = df[0:10000]\n",
        "df = onehot_encode_pd(df,'R')\n",
        "df = onehot_encode_pd(df,'C')\n",
        "\n",
        "# Create lag features\n",
        "\n",
        "df = create_lag_feature(df, lags = range(40), features = ['u_in', 'inhaled_diff_lag', 'inhaled_air',]).fillna(0)\n",
        "\n",
        "# Split data to train, val, test\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df, 'pressure', 0.2, 42)\n",
        "\n",
        "# Choose scaler and scale it!\n",
        "\n",
        "scaler = get_scaler('robust')\n",
        "X_train_arr = scaler.fit_transform(X_train)\n",
        "X_val_arr = scaler.transform(X_val)\n",
        "X_test_arr = scaler.transform(X_test)\n",
        "\n",
        "y_train_arr = scaler.fit_transform(y_train)\n",
        "y_val_arr = scaler.transform(y_val)\n",
        "y_test_arr = scaler.transform(y_test)\n",
        "\n",
        "# Choose batch size and make it a model friendly dtype\n",
        "\n",
        "batch_size = 80\n",
        "\n",
        "train_features = torch.Tensor(X_train_arr)\n",
        "train_targets = torch.Tensor(y_train_arr)\n",
        "val_features = torch.Tensor(X_val_arr)\n",
        "val_targets = torch.Tensor(y_val_arr)\n",
        "test_features = torch.Tensor(X_test_arr)\n",
        "test_targets = torch.Tensor(y_test_arr)\n",
        "\n",
        "train = TensorDataset(train_features, train_targets)\n",
        "val = TensorDataset(val_features, val_targets)\n",
        "test = TensorDataset(test_features, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "8b04IfDGCtSV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "HFuJSQnLocLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose parametres\n",
        "\n",
        "input_dim = len(X_train.columns)\n",
        "output_dim = 1\n",
        "hidden_dim = 80\n",
        "layer_dim = 3\n",
        "batch_size = 80\n",
        "dropout = 0.2\n",
        "n_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model_params = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}"
      ],
      "metadata": {
        "id": "PwVwgkpyKXJw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose model type: rnn, lstm, gru\n",
        "\n",
        "model_type = 'lstm'"
      ],
      "metadata": {
        "id": "tI86N8qI3FSw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, loss function and optimizer \n",
        "\n",
        "model = get_model(model_type, model_params).to(device)\n",
        "\n",
        "loss_fn = nn.L1Loss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "NvyL9_kZxTBv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model path\n",
        "model_path = file_path + f'/{model}'"
      ],
      "metadata": {
        "id": "23AB7kb5f1pp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim, model_path = model_path)\n",
        "opt.plot_losses(file_path = file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "9hUkI9_hv8EG",
        "outputId": "f9020ebb-6898-4323-fccb-47deb8d8d78c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/10] Training loss: 0.6311\t Validation loss: 0.4122\n",
            "[2/10] Training loss: 0.4680\t Validation loss: 0.3474\n",
            "[3/10] Training loss: 0.4223\t Validation loss: 0.3443\n",
            "[4/10] Training loss: 0.3972\t Validation loss: 0.3379\n",
            "[5/10] Training loss: 0.3883\t Validation loss: 0.3334\n",
            "[6/10] Training loss: 0.3797\t Validation loss: 0.3398\n",
            "[7/10] Training loss: 0.3630\t Validation loss: 0.3410\n",
            "[8/10] Training loss: 0.3663\t Validation loss: 0.3416\n",
            "[9/10] Training loss: 0.3666\t Validation loss: 0.3487\n",
            "[10/10] Training loss: 0.3612\t Validation loss: 0.3542\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "rF2gVDisswWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model if needed\n",
        "\n",
        "\n",
        "```\n",
        "the_model = get_model('lstm', model_params).to(device)\n",
        "the_model = the_model.load_state_dict(torch.load('models/lstm'))\n",
        "the_model.eval()\n",
        "opt = Optimization(model=the_model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pPE5DYjyv7DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)\n",
        "df_result = format_predictions(predictions, values, X_test, scaler)"
      ],
      "metadata": {
        "id": "L_MbMveBszcQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "VVjehRbyLS-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results for all observations\n",
        "\n",
        "result_metrics_all = calculate_metrics(df_result)\n",
        "result_metrics_all"
      ],
      "metadata": {
        "id": "Z4wNQFdcK7NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566163da-28fa-421c-d7d8-f1ea6cc1ff6b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 3.034091, 'r2': 0.5689531508420651, 'rmse': 5.746360290278827}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Result only for u_out = 0\n",
        "\n",
        "dff = pd.DataFrame(df_result)\n",
        "dff['id'] = dff.index\n",
        "idx0 = df[df.u_out == 0].index\n",
        "idx = pd.DataFrame(idx0)\n",
        "idx.rename(columns = {0:'id'}, inplace = True)\n",
        "res = pd.merge(dff,idx, on ='id', how = 'inner')\n",
        "\n",
        "result_metrics_out0 = calculate_metrics(res)\n",
        "result_metrics_out0"
      ],
      "metadata": {
        "id": "mcVGiWwpK_Gm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d86ca61-83e3-417c-d9a2-49174606ed15"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 5.534005, 'r2': 0.2953861425090941, 'rmse': 8.200562285706866}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save"
      ],
      "metadata": {
        "id": "moHsE0Ytvdqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for .csv\n",
        "\n",
        "out0 = pd.DataFrame(result_metrics_out0, index = [0])\n",
        "out0['data'] = 'u_out=0'\n",
        "all_res = pd.DataFrame(result_metrics_all,index = [1])\n",
        "all_res['data'] = 'all'\n",
        "errors = pd.concat([out0,all_res])\n",
        "\n",
        "params_to_save = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout,\n",
        "                'batch_size' : batch_size,\n",
        "                'n_epochs' : n_epochs,\n",
        "                'learning_rate' : learning_rate,\n",
        "                'weight_decay' : weight_decay,\n",
        "                'model_type' : model_type}\n",
        "\n",
        "params = pd.DataFrame(params_to_save, index = [0])"
      ],
      "metadata": {
        "id": "ciiprD9otoNo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results, errors, parametres\n",
        "\n",
        "df_result.to_csv(file_path + '/df_result.csv')\n",
        "errors.to_csv(file_path + '/errors.csv')\n",
        "params.to_csv(file_path + '/params.csv')"
      ],
      "metadata": {
        "id": "3Rdy54WWsrMw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename file\n",
        "mae = round(errors.mae[0],3)\n",
        "os.rename(file_path,\"models/\" + f'{model_type}_mae{format(mae,\".3f\")}')"
      ],
      "metadata": {
        "id": "R_uX0WqsvUOy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GVTNYX4o_T-U"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}