{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/final-projects-ventilator-pressure-prediction/blob/main/vp_colab/ventilator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**This demo version uses only 1% of data**"
      ],
      "metadata": {
        "id": "GnWRMHXIgB0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BV2y2HBV-oNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "a2cwnVba9rMD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import datetime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "v1x2-QxM-qOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a file for models\n",
        "file_path = f'models/{datetime.datetime.now().strftime(\"%Y %H:%M\")}'\n",
        "if os.path.exists(file_path) == False:\n",
        "  os.makedirs(file_path)\n"
      ],
      "metadata": {
        "id": "yIUjfLZH8UM5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/panekvit/su_data.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKd4Ea9LfTe2",
        "outputId": "3c36325b-e5b5-4a4d-d651-bd9b0b33d70d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'su_data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data = pd.read_csv('/content/su_data/data.csv')\n",
        "target_pres = data.pressure.copy()"
      ],
      "metadata": {
        "id": "telloKHT-skW"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "wFxIgTWh_csW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "PS59zjkzCoEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['step'] = list(range(80))*data['breath_id'].nunique()\n",
        "data['u_in_min'] = data['breath_id'].map(data.groupby('breath_id')['u_in'].min())\n",
        "\n",
        "data['u_in_diff'] = data['u_in'].diff()\n",
        "data.loc[data['step']<1, 'u_in_diff'] = 0\n",
        "\n",
        "data['time_diff'] = data['time_step'].diff()\n",
        "data.loc[data['step']<1, 'time_diff'] = 0\n",
        "\n",
        "data['inhaled_air'] = data['time_diff']*data['u_in']\n",
        "\n",
        "data['inhaled_diff_lag'] = data['inhaled_air'].diff().shift(1)\n",
        "data.loc[data['step']<2, 'inhaled_diff_lag'] = 0\n",
        "\n",
        "\n",
        "\n",
        "#data['pressure'] = data['pressure'].diff()\n",
        "#data.loc[data['step']<1, 'pressure'] = 0\n",
        "\n",
        "#Make a lead\n",
        "#df['pressure_lead'] = df.pressure.shift(-1)"
      ],
      "metadata": {
        "id": "mU2gpMgj_7R_"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lag functions\n"
      ],
      "metadata": {
        "id": "WjdCaEVWDHV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_all(df, lags):\n",
        "  res = df.copy()\n",
        "  for lag in lags:\n",
        "    df1 = df.copy()\n",
        "    df1 = df1.shift(lag)\n",
        "    res = pd.merge(res,df1.rename(columns = lambda x: x+f'_{lag}lag'),left_index=True,right_index=True)\n",
        "  \n",
        "  return res\n",
        "\n",
        "def create_lag_feature(df, lags, features):\n",
        "  res = df.copy()\n",
        "  for feature in features:\n",
        "    for lag in lags:\n",
        "      df1 = df.copy()\n",
        "      df1 = df1[feature].shift(lag)\n",
        "      df1 = pd.DataFrame(df1)\n",
        "      res = pd.merge(res,df1.rename(columns = lambda x: x+f'_{lag}lag'),left_index=True,right_index=True)    \n",
        "      res.loc[res['step']<lag, feature+f'_{lag}lag'] = 0\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "kzMebL8lDGsT"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN, LSTM, GRU"
      ],
      "metadata": {
        "id": "rt4FaK8VCU-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rMDxaevLU_E4",
        "outputId": "6da62bbe-c7d8-4ec3-bc44-36c39b88af16"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions and Classes"
      ],
      "metadata": {
        "id": "Y5EFPKXynEk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess\n"
      ],
      "metadata": {
        "id": "3ny2dSzZnJh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHot encoding\n",
        "\n",
        "def onehot_encode_pd(df, col_name):\n",
        "    dummies = pd.get_dummies(df[col_name], prefix=col_name)\n",
        "    return pd.concat([df, dummies], axis=1).drop(columns=[col_name])\n",
        "\n",
        "# Feature label split\n",
        "\n",
        "def feature_label_split(df, target_col):\n",
        "    y = df[[target_col]]\n",
        "    X = df.drop(columns=[target_col])\n",
        "    return X, y\n",
        "\n",
        "# Split function\n",
        "\n",
        "def train_val_test_split(df, target_col, test_ratio, random_state):\n",
        "    val_ratio = test_ratio / (1 - test_ratio)\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False, random_state=random_state)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False, random_state=random_state)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Scalers\n",
        "\n",
        "def get_scaler(scaler):\n",
        "    scalers = {\n",
        "        \"minmax\": MinMaxScaler,\n",
        "        \"standard\": StandardScaler,\n",
        "        \"maxabs\": MaxAbsScaler,\n",
        "        \"robust\": RobustScaler,\n",
        "    }\n",
        "    return scalers.get(scaler.lower())()\n"
      ],
      "metadata": {
        "id": "QfMuup4ZCXzy"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "6Tp9xljlnQSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # RNN layers\n",
        "        self.rnn = nn.RNN(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, h0 = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fD9NjNS0HfYJ"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "z_2yP29aJG_4"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :].to(device)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "-pcNYmfBJL3C"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        \"rnn\": RNNModel,\n",
        "        \"lstm\": LSTMModel,\n",
        "        \"gru\": GRUModel,\n",
        "    }\n",
        "    return models.get(model.lower())(**model_params)"
      ],
      "metadata": {
        "id": "kbmh1ufvJOxJ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and eval"
      ],
      "metadata": {
        "id": "8TCVjphGndP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "    \n",
        "    def train_step(self, x, y):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size=80, n_epochs=50, n_features=1, model_path = 'model'):\n",
        "\n",
        "      for epoch in range(1, n_epochs + 1):\n",
        "          batch_losses = []\n",
        "          for x_batch, y_batch in train_loader:\n",
        "              x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
        "              y_batch = y_batch.to(device)\n",
        "              loss = self.train_step(x_batch, y_batch)\n",
        "              batch_losses.append(loss)\n",
        "          training_loss = np.mean(batch_losses)\n",
        "          self.train_losses.append(training_loss)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              batch_val_losses = []\n",
        "              for x_val, y_val in val_loader:\n",
        "                  x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
        "                  y_val = y_val.to(device)\n",
        "                  self.model.eval()\n",
        "                  yhat = self.model(x_val)\n",
        "                  val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                  batch_val_losses.append(val_loss)\n",
        "              validation_loss = np.mean(batch_val_losses)\n",
        "              self.val_losses.append(validation_loss)\n",
        "\n",
        "          if (epoch <= 10) | (epoch % 50 == 0):\n",
        "              print(\n",
        "                  f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "              )\n",
        "      torch.save(self.model.state_dict(), model_path)\n",
        "      val_loss = pd.DataFrame(self.val_losses)\n",
        "      train_loss = pd.DataFrame(self.train_losses)\n",
        "      losses = pd.concat([train_loss, val_loss], axis = 1)\n",
        "      losses.columns = ['train_loss','val_loss']\n",
        "      losses.to_csv(file_path + '/losses.csv')\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
        "      with torch.no_grad():\n",
        "          predictions = []\n",
        "          values = []\n",
        "          for x_test, y_test in test_loader:\n",
        "              x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
        "              y_test = y_test.to(device)\n",
        "              self.model.eval()\n",
        "              yhat = self.model(x_test)\n",
        "              predictions.append(yhat.to('cpu').detach().numpy())\n",
        "              values.append(y_test.to('cpu').detach().numpy())\n",
        "\n",
        "      return predictions, values\n",
        "\n",
        "    def plot_losses(self, file_path):\n",
        "      plt.plot(self.train_losses, label=\"Training loss\")\n",
        "      plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "      plt.legend()\n",
        "      plt.title(\"Losses\")\n",
        "      fig1 = plt.gcf()\n",
        "      plt.show()\n",
        "      fig1.savefig(file_path + '/plot_loss.png', dpi=100)\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "PtDwfDyUJYTr"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "NYAP_2k7nuaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaler, df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = scaler.inverse_transform(df[col])\n",
        "    return df\n",
        "\n",
        "\n",
        "def format_predictions(predictions, values, df_test, scaler):\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
        "    df_result = df_result.sort_index()\n",
        "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
        "    return df_result\n",
        "\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    return {'mae' : mean_absolute_error(df.value, df.prediction),\n",
        "            'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
        "            'r2' : r2_score(df.value, df.prediction)}\n",
        "\n"
      ],
      "metadata": {
        "id": "l9JEhyMnKl9x"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "a0trz48zn8cE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part you are free to choose parameters, models, scalers and so on\n",
        "\n",
        "Or you can dive deeper into the code ofc:) "
      ],
      "metadata": {
        "id": "cLVFrhzfkf9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lagged features\n",
        "features = ['u_in', 'inhaled_diff_lag', 'inhaled_air']\n",
        "n_lags = 40\n",
        "\n",
        "# Scalers: 'minmax', 'standard', 'maxabs', 'robust'\n",
        "scaler_name = 'maxabs'\n",
        "\n",
        "# Dropout\n",
        "drop_out = 0\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Models: 'rnn', 'lstm', 'gru'\n",
        "model_type = 'lstm'"
      ],
      "metadata": {
        "id": "Dd559yHhkzhl"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "jR3V5UBcoZBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick data and do OneHot\n",
        "\n",
        "df = data.copy()\n",
        "df = onehot_encode_pd(df,'R')\n",
        "df = onehot_encode_pd(df,'C')\n",
        "\n",
        "# Create lag features\n",
        "\n",
        "df = create_lag_feature(df, lags = range(n_lags), features =features).fillna(0)\n",
        "\n",
        "# Split data to train, val, test\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df, 'pressure', 0.2, 42)\n",
        "\n",
        "# Choose scaler and scale it!\n",
        "\n",
        "scaler = get_scaler(scaler_name)\n",
        "\n",
        "X_train_arr = scaler.fit_transform(X_train)\n",
        "X_val_arr = scaler.transform(X_val)\n",
        "X_test_arr = scaler.transform(X_test)\n",
        "\n",
        "y_train_arr = scaler.fit_transform(y_train)\n",
        "y_val_arr = scaler.transform(y_val)\n",
        "y_test_arr = scaler.transform(y_test)\n",
        "\n",
        "# Choose batch size and make it a model friendly dtype\n",
        "\n",
        "batch_size = 80\n",
        "\n",
        "train_features = torch.Tensor(X_train_arr)\n",
        "train_targets = torch.Tensor(y_train_arr)\n",
        "val_features = torch.Tensor(X_val_arr)\n",
        "val_targets = torch.Tensor(y_val_arr)\n",
        "test_features = torch.Tensor(X_test_arr)\n",
        "test_targets = torch.Tensor(y_test_arr)\n",
        "\n",
        "train = TensorDataset(train_features, train_targets)\n",
        "val = TensorDataset(val_features, val_targets)\n",
        "test = TensorDataset(test_features, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "8b04IfDGCtSV"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "HFuJSQnLocLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose parametres\n",
        "\n",
        "input_dim = len(X_train.columns)\n",
        "output_dim = 1\n",
        "hidden_dim = 80\n",
        "layer_dim = 3\n",
        "batch_size = 80\n",
        "dropout = drop_out\n",
        "n_epochs = num_epochs\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model_params = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}"
      ],
      "metadata": {
        "id": "PwVwgkpyKXJw"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, loss function and optimizer \n",
        "\n",
        "model = get_model(model_type, model_params).to(device)\n",
        "\n",
        "loss_fn = nn.L1Loss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "NvyL9_kZxTBv"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model path\n",
        "model_path = file_path + f'/{model}'"
      ],
      "metadata": {
        "id": "23AB7kb5f1pp"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim, model_path = model_path)\n",
        "opt.plot_losses(file_path = file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9hUkI9_hv8EG",
        "outputId": "22b70225-7008-47ec-ecfd-1dc44d9726f8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/100] Training loss: 0.0480\t Validation loss: 0.0381\n",
            "[2/100] Training loss: 0.0328\t Validation loss: 0.0296\n",
            "[3/100] Training loss: 0.0281\t Validation loss: 0.0259\n",
            "[4/100] Training loss: 0.0254\t Validation loss: 0.0243\n",
            "[5/100] Training loss: 0.0235\t Validation loss: 0.0221\n",
            "[6/100] Training loss: 0.0220\t Validation loss: 0.0211\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-7498813439da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-126-9b4a4e4cf184>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, batch_size, n_epochs, n_features, model_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m               \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m               \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m               \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-126-9b4a4e4cf184>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Updates parameters and zeroes gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Returns the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "rF2gVDisswWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model if needed\n",
        "\n",
        "\n",
        "```\n",
        "the_model = get_model('lstm', model_params).to(device)\n",
        "the_model = the_model.load_state_dict(torch.load('models/lstm'))\n",
        "the_model.eval()\n",
        "opt = Optimization(model=the_model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pPE5DYjyv7DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)\n",
        "df_result = format_predictions(predictions, values, X_test, scaler)"
      ],
      "metadata": {
        "id": "L_MbMveBszcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is just 2.5% of used data in this version, so you can see better how does it look\n",
        "# btw Fully trained models are much more precise, we will show it in presentation\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
        "plt.plot(range(len(df_result[0:2000])), df_result.value[0:2000], label = 'test data')\n",
        "plt.plot(range(len(df_result[0:2000])), df_result.prediction[0:2000], label = 'prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XEQ_WXoOgdhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "VVjehRbyLS-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results for all observations\n",
        "\n",
        "result_metrics_all = calculate_metrics(df_result)\n",
        "result_metrics_all"
      ],
      "metadata": {
        "id": "Z4wNQFdcK7NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result only for u_out = 0\n",
        "\n",
        "dff = pd.DataFrame(df_result)\n",
        "dff['id'] = dff.index\n",
        "idx0 = df[df.u_out == 0].index\n",
        "idx = pd.DataFrame(idx0)\n",
        "idx.rename(columns = {0:'id'}, inplace = True)\n",
        "res = pd.merge(dff,idx, on ='id', how = 'inner')\n",
        "\n",
        "result_metrics_out0 = calculate_metrics(res)\n",
        "result_metrics_out0"
      ],
      "metadata": {
        "id": "mcVGiWwpK_Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save"
      ],
      "metadata": {
        "id": "moHsE0Ytvdqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for .csv\n",
        "\n",
        "out0 = pd.DataFrame(result_metrics_out0, index = [0])\n",
        "out0['data'] = 'u_out=0'\n",
        "all_res = pd.DataFrame(result_metrics_all,index = [1])\n",
        "all_res['data'] = 'all'\n",
        "errors = pd.concat([out0,all_res])\n",
        "\n",
        "params_to_save = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout,\n",
        "                'batch_size' : batch_size,\n",
        "                'n_epochs' : n_epochs,\n",
        "                'learning_rate' : learning_rate,\n",
        "                'weight_decay' : weight_decay,\n",
        "                'model_type' : model_type}\n",
        "\n",
        "params = pd.DataFrame(params_to_save, index = [0])"
      ],
      "metadata": {
        "id": "ciiprD9otoNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results, errors, parametres\n",
        "\n",
        "df_result.to_csv(file_path + '/df_result.csv')\n",
        "errors.to_csv(file_path + '/errors.csv')\n",
        "params.to_csv(file_path + '/params.csv')"
      ],
      "metadata": {
        "id": "3Rdy54WWsrMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename file\n",
        "mae = round(errors.mae[0],3)\n",
        "os.rename(file_path,\"models/\" + f'{model_type}_mae{format(mae,\".3f\")}')"
      ],
      "metadata": {
        "id": "R_uX0WqsvUOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}